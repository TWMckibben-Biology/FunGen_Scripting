# Analysis Log for A Comparison of 25 RNA-seq Pipelines as an Educational Tool for Functional Genomics

## Description & Purpose
words<br/>
are
great
so
fill
this
in.

## Abbreviations
EAS = Easley HPC  
HOP = Hopper HPC
FunGen = TSS Functional Genomics Class  


### 09-07-2021 Downloading Data; AC
Downloaded 10 samples using sratoolkit on EAS.Used the prefetch/dump combination code from the utility of blood transcriptome repo. 
FASTQ files were split and dumped in `/scratch/adc0032/DpulexCaloricWD/SRRs`using the script `download_SRA.sh` which can be found in 
`/home/adc0032/workflows`. I used the SRA_Acc_List.txt downloaded from SRA run selector on the web for this bioproject (insert id).

This script has no header, so it was called using my general job submisson script `gen_slurm_submit.sh` also in `~/workflows`.
One sample did not download through the first pass (SRR6819018), so I move it to a new input file (grep "SRR6819018" SRA_Acc_list.txt > redo_acc_list.txt),
and used that as input to `download_SRA.sh` on a second pass, with no issues. 

### 09-08-2021 Project Organization; AC
Created a github repository for this project. Gave it a general structure, but have not filled in many details. 
Added all of the scripts previously generated by past FunGen students onto EAS (`rsync`).
Mapped out the analysis pipeline, indicating if the scripts for each step were present or whether there needed to be any modifications.
[The analysis map](https://excalidraw.com/#json=6318931916619776,W88Xasevi5iT8um0p4cqJg) was generated with 
[Excalidraw](https://excalidraw.com) and will be updated alongside this log. 

### 09-13-2021 Writing support scripts ; AC
revised `download_SRA_a.sh` to increase reproducibility. Organized for usage in an array or with the proper arguments at the command line. 

Generated support scripts for:

1. fastq file quality check `run_fastqc.sh`
2. trimming adaptors and low quality sequences `run_trimmomatic.sh`

### 09-14-2021 Meeting and requesting software; AC
Met with collaborators: requested github ids, code, and discussed adding new pipeline, salmon  

requested software on easley: stringtie, gffread, kallisto, htseq, parallel

### 09-20-2021 - 09-24-2021 HPC offline

### 09-27-2021 
Kallisto and HTseq added 
need parallel for pipeline, but testing on HOP until installed on EAS

### 10-02-2021
installed parallel on EAS locally, works just fine!

### 10-12-2021
Pulled down Daphnia_pulex.[scaffolds.fa && gff3] from TSS box folder (which should mirror google drive files from FunGen).  
Ran `md5sum` to make sure everything was copacetic.   
generated `prep_reference.sh` script: generates indicies for hisat and star; generates gtf .ss and .exon files from gff3  
script submits to slurm using `prep_ref_slurm.sh`  
Changes made from FunGen workflow and script files on google drive

- using `--sjdbGTFtagExonParentTranscript transcript_id` to use transcript_id as tag name to be used as exonsâ€™ transcript-parents relationship in star
- using `--sjdbGTFfile ${GTF}` to add annotation information to genome index; this step was done at the point of running star in the FunGen workflows; moved it to mirror hisat pipeline.
- using `--genomeSAindexNbases 12` due to a warning in the test run of this script indicating that the default of 14 was too high and would likely result in segmentation errors in downstream mapping in star

### 10-13-2021

updated `download_SRA.sh` to be called within a slurm script `prep_reads_slurm.sh`. *note: `download_SRA_a.sh` was renamed to `download_SRA.sh`*
generated `prep_reads_slurm.sh`: `download_SRA.sh` downloads reads from NCBI using SRR#'s (originally called SRA_Acc_List.txt; now dpulex.calor.jf); `run_fastqc.sh` runs twice, once after downloading and once after trimming; `run_trimmomatic.sh` trims reads 
using the same parameters outlined in FunGen trimming workflow.

### 10-14-2021

generated `run_hisat2.sh` script: maps trimmed reads to reference using hisat2, output is piped from hisat2 into samtools to generate bams; indexes bams   
generated `run_star.sh` script: maps trimmed reads to refernce using star, output is piped from star into samtools to generate bams; indexes bams  
scripts submit to slurm using `map_reads_slurm.sh`  
Changes made from FunGen workflow and script files on google drive:  

- intermediate sam files are not generated, piping from mappers directly into samtools sort to output sorted bam
- no longer indicating strandedness in `run_hisat2.sh` because we are not using this information during mapping for STAR (no way to indicate using STAR)
- using `--readFilesCommand gunzip -c` to prevent having to uncompress fastq files in star
- using `--outStd SAM` to send SAM output from star to stdout; this allows piping into samtools
